# AI-Generated-CTI

This project focuses on **Generation and Evaluation of Synthetic Cyber Threat Intelligence** using resource-efficient fine-tuned language models.

---

## Overview

The synthetic CTI samples were generated using a **4-bit quantized [TinyLlama model](https://huggingface.co/unsloth/tinyllama-bnb-4bit)**, which was fine-tuned on cybersecurity-related corpus.  
Generated samples then underwent a multifaceted evaluation process, with one crucial step being detection using a custom-built hybrid detection system.

---

## Detection System

A hybrid detection system was developed to identify fake vs. real CTI descriptions. It combines two models from the **BERT family**:

- [**DistilBERT**](https://huggingface.co/distilbert/distilbert-base-uncased)  
- [**BERT-Tiny**](https://huggingface.co/prajjwal1/bert-tiny)

---

## Survey

Additionally, a subset of 100 CTI samples (50 generated by fine-tuned TinyLlama and 50 real CTI descriptions) was evaluated by:

- Cybersecurity experts (students and experienced analysts)  
- Four large language models (LLMs)  

The evaluation results, presented in plots, can be found in the [`survey/`](./survey) directory.

---

## Corpus

The dataset used for TinyLlama fine-tuning includes multiple sources:

- **APTnotes (2008–2024)** – a collection of Advanced Persistent Threat (APT) reports from the [APTnotes repository](https://github.com/aptnotes/data/), downloaded using tools from [APTnotes Tools](https://github.com/aptnotes/tools) and collected in the local `APTnotes` directory. 
- Additional CTI datasets from the [Hugging Face Datasets platform](https://huggingface.co/datasets).
