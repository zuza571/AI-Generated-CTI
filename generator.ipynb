{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATOR PART - Python 3.12\n",
    "```python3 -m venv venv\n",
    "\\venv\\Scripts\\Activate.ps1 # for Windows\n",
    "pip install -r requirements.txt\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Zuza\\MAGISTERKA\\AI-Generated-CTI\\venv\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.8: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5080. Num GPUs = 1. Max memory: 15.92 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: unsloth/tinyllama-bnb-4bit can only handle sequence lengths of at most 2048.\n",
      "But with kaiokendev's RoPE scaling of 2.0, it can be magically be extended to 4096!\n",
      "Unsloth 2025.4.8 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n",
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model_name = \"tinyllama-bnb-4bit\"\n",
    "\n",
    "max_seq_length = 4096\n",
    "dtype = None            # autodetect\n",
    "load_in_4bit = True     # enable 4-bit quantization to reduce memory usage\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=f\"{model_name}-finetuned-causal-2nd\", # if want to download: model_name=f\"unsloth/{model_name}\"\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "rank = 32\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=rank,                                         # rank of the finetuning; larger values use more memory, but increase accuracy; use one of: 8, 16, 32, 64, 128\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "                    # \"embed_tokens\", \"lm_head\"],     # for continual pretraining\n",
    "    lora_alpha=rank,                                # scaling factor for finetuning; suggested value = r\n",
    "    lora_dropout=0,                                 # 0 is optimized\n",
    "    bias=\"none\",                                    # \"none\" is optimized\n",
    "    use_gradient_checkpointing=\"unsloth\",           # \"unsloth\" for long context finetuning\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "# save the model\n",
    "# model.save_pretrained(model_name)\n",
    "# tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# for continued pretraining - raw text\n",
    "def format_prompt(data, data_filed=\"text\"):\n",
    "    if isinstance(data_filed, str):\n",
    "        return {\"text\": [example + EOS_TOKEN for example in data[data_filed]]}\n",
    "    else:\n",
    "        return {\"text\": [\" \".join(str(data[key][i]).strip() for key in data_filed if key in data) + EOS_TOKEN for i in range(len(data[data_filed[0]]))]}\n",
    "\n",
    "apt_reports = load_dataset(\"json\", data_files=\"aptnotes_dataset.jsonl\", split=\"train\")\n",
    "cti_reports = load_dataset(\"mrminhaz/CTI-Reports\", split=\"train\")\n",
    "cti_rcm_reports = load_dataset(\"skrishna/cti-rcm-2021\", split=\"train\")\n",
    "\n",
    "# first iteration\n",
    "dataset_part1 = apt_reports.map(format_prompt, batched=True, remove_columns=apt_reports.column_names)\n",
    "dataset_part2 = cti_reports.map(format_prompt, batched=True, remove_columns=cti_reports.column_names, fn_kwargs={\"data_filed\": [\"input\", \"output\"]})\n",
    "dataset_part3 = cti_rcm_reports.map(format_prompt, batched=True, remove_columns=cti_rcm_reports.column_names, fn_kwargs={\"data_filed\": \"Description\"})\n",
    "\n",
    "dataset = concatenate_datasets([dataset_part1, dataset_part2, dataset_part3])\n",
    "\n",
    "# second iteration\n",
    "cti_10k = load_dataset(\"ctitools/orkl_cleaned_10k\", split=\"train\")\n",
    "dataset_part4 = cti_10k.map(format_prompt, batched=True, remove_columns=cti_10k.column_names)\n",
    "dataset = concatenate_datasets([dataset, dataset_part4])\n",
    "\n",
    "# TODO: before the last iteration remove non unicode or non ascii characters from the dataset and start the learning from the 1st model!\n",
    "\n",
    "# third iteration\n",
    "# TODO: train test split 0.1 or sth like this as so many samples will be generated\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.3, shuffle=True, seed=42)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "# MALICIOUS ACTIVITY REPORT\n",
      "\n",
      "## Deep Analysis of a Recent Lokibot Attack\n",
      "\n",
      "**17 November 2021**  \n",
      "**Author: Gaetano Pellegrino**\n",
      "\n",
      "### 1. Purpose\n",
      "\n",
      "As an infostealer, Lokibot can extract and then exfiltrate sensitive information from many popular applications. Although Lokibot was discovered back in 2015, it is still being distributed and is a serious threat to consumers and organizations. The purpose of this report is to:\n",
      "\n",
      "1. Provide a fresh and detailed view of the Lokibot attack chain: from the email attachment to the Lokibot malware itself.\n",
      "2. Explain the capabilities and purpose of each artifact involved in the attack.\n",
      "3. Describe how Lokibot uses process hollowing, API hashing, various obfuscation algorithms, and other techniques to thwart analysis and avoid detection.\n",
      "4. Release a body of knowledge and tools, such as the source code for a Lokibot vaccine, that would enhance the detection and prevention of this menace.\n",
      "\n",
      "### 2. Overview\n",
      "\n",
      "Lokibot was first seen on May 3, 2015, when a hacker nicknamed Lokistov or Carter published a sales announcement for Lokibot. At that time, Lokibot’s focus was limited to attacking cryptocurrency wallets. Some researchers believe Lokibot’s original codebase was stolen from the author and resold at a lower price. Others think that the malware was patched by some actor who had no access to the source code; having fully analyzed a recent sample, we at Infoblox share this view.\n",
      "\n",
      "Nowadays, Lokibot is an information-stealing malware with keylogging capability and application-specific functions for targeting popular web browsers, FTP clients, email applications, password management tools, and even poker game platforms. Variants of Lokibot seem to have functions tailored to specific applications, but the malware’s overall structure has not changed much over the last few years. What has changed are the early stages of the attack chain: Lokibot’s capability to be extracted from an attached ISO image, downloaded from a link in a PDF document, installed via a document by exploiting a vulnerability in Microsoft Office, or delivered as a .NET executable via an NSIS installer.\n",
      "\n",
      "However, in the case reported, the attack chain was less sophisticated, because the installer dropped the executable directly into the file system. Recent Lokibot attacks are more sophisticated, have more stages, and apply obfuscation techniques.\n",
      "\n",
      "Lokibot has been discussed in great detail in previous research. Our goal here is to add to this body of knowledge by providing a fresh and exhaustive overview of the entire Lokibot attack chain for a campaign that occurred in early June 2021. In that campaign, we observed the following main techniques at various stages of the attack:\n",
      "\n",
      "| MITRE ATT&CK ID | Technique | Description |\n",
      "|------------------|-----------|-------------|\n",
      "| T1566 | Phishing | Lokibot is usually delivered via email, with mass propagation campaigns. |\n",
      "| T1204.002 | User Execution: Malicious File | Lokibot is usually executed through malicious documents, AutoIt scripts, and Windows installers. |\n",
      "| T1071.001 | Application Layer Protocol: Web Protocols | Lokibot uses HTTP to communicate with the command and control (C&C). |\n",
      "| T1564.001 | Hide Artifacts: Hidden Files and Directories | Lokibot creates several files in a hidden directory. It is also capable of moving itself into a hidden directory as part of the persistence-setting process. |\n",
      "| T1027 | Obfuscated Files or Information | Lokibot is usually protected by at least one obfuscation technique. |\n",
      "| T1027.002 | Obfuscated Files or Information: Software Packing | Lokibot may be protected by at least one form of the packing algorithm. |\n",
      "| T1055.012 | Process Injection: Process Hollowing | It has been reported that Lokibot uses the Process Hollowing technique to inject itself into other processes. |\n",
      "| T1082 | System Information Discovery | Lokibot has the capability of getting the architecture, screen resolution, operating system version, and other system information. |\n",
      "| T1016 | System Network Configuration Discovery | Lokibot has the capability of getting the domain name of the computer it infected. |\n",
      "| T1033 | System Owner/User Discovery | Lokibot has the capability of getting the username of a logged-in user. |\n",
      "| T1560.002 | Archive Collected Data: Archive via Library | Lokibot is capable of compressing the stolen data before sending it to the C&C. This report discusses a sample by using aPLib, a freeware compression library, to compress the stolen data prior to its exfiltration. |\n",
      "| T1005 | Data from Local System | Lokibot looks for specific files and attempts to exfiltrate them. |\n",
      "| T1555 | Credentials from Password Stores | Lokibot is capable of stealing passwords from FTP clients, email clients, and other applications. |\n",
      "| T1555.003 | Credentials from Password Stores: Credentials from Web Browsers | Lokibot is capable of stealing passwords saved by a variety of browsers. |\n",
      "| T1041 | Exfiltration Over C&C Channel | Lokibot exfiltrates stolen information via a C&C channel. |\n",
      "\n",
      "### 3. The Attack Chain\n",
      "\n",
      "Since June 2021, the Infoblox Global Intelligence Analytics team has observed a significant increase in the number of campaigns delivering Lokibot malware. The campaigns are still targeting Italy, Greece, China, Vietnam, Argentina, and other countries. This section provides an overview of the entire attack chain used in these campaigns. Each subsequent section focuses on a separate link in the attack chain.\n",
      "\n",
      "The attack chain starts as an email with an attached compressed RAR archive (a feature of all Lokibot campaigns we have studied) and campaign-specific body text similar to the following:\n",
      "\n",
      "> Can you please let us know when the invoice no. 2215301 will be paid?  \n",
      "> According to our account department we're yet to receive your payment.  \n",
      "> Thanks.  \n",
      "> I wish you a nice day!  \n",
      "> Best Regards  \n",
      "> [REDACTED]  \n",
      "> Purchasing Department  \n",
      "> [REDACTED] S.p.A.  \n",
      "> Phone: +39 051 [REDACTED]  \n",
      "> Mobile: +39 333 [REDACTED]  \n",
      "> Fax: +39 051 [REDACTED]  \n",
      "> Email: [REDACTED]@[REDACTED]  \n",
      "\n",
      "In this case, the threat actor sent spoofed corporate emails. The sender’s name, phone numbers, and other information (redacted in the example) belonged to an employee of the attacked corporation, an Italian mobile banking company, and were probably obtained from the data black market or from previous attacks. The attachment is a Windows executable masked as a PDF file and named “invoice no. XXXXXXX·pdf.rar”, where XXXXXXX is a number and “·pdf” is a fake extension. Because Windows hides the file extension by default, the victim does not see “.exe”. The executable is a Windows installer generated with a legitimate tool, Nullsoft Scriptable Install System (NSIS), henceforth referred to as the NSIS installer.\n",
      "\n",
      "Once opened, the NSIS installer decompresses and drops two files with randomly generated names, in this case cgttxpglckz and a01jkkyi4ridof2orcun, into the file system. cgttxpglckz contains shellcode that (1) the NSIS installer loads into memory and executes and that (2) consists of what is commonly known as a stub: a piece of code responsible for decrypting further code and executing it. The code decrypted by the stub uses process hollowing to load, decrypt, and inject a01jkkyi4ridof2orcun into a newly spawned process. Although the encrypted a01jkkyi4ridof2orcun contains binary data without any apparent meaning, decryption reveals its true content: a sample of Lokibot malware. For the rest of this report, we will refer to cgttxpglckz as the Loader and to a01jkkyi4ridof2orcun as the Encrypted Lokibot.\n",
      "\n",
      "In the last link of the chain, Lokibot runs an array of functions each targeting specific applications with the goal of harvesting files that contain sensitive information.\n",
      "\n",
      "### 4. The NSIS Installer\n",
      "\n",
      "Threat actors password-protect email attachments. However, in several Lokibot campaigns we observed in June 2021, no password was required to open the archive, because it contained an NSIS installer: a legitimate, open-source utility for creating installers for Windows applications. NSIS ships with a scripting language that lets clients define and control almost every aspect of installation, including uncompressing a file included in the installation bundle.\n",
      "\n",
      "The adoption of an NSIS installer early in the attack confers several time-saving benefits. First, NSIS installers provide a compression layer, which helps the artifacts escape detection by anti-malware. Second, the victim does not need to type a password to run the malware. These factors reduce the time gap between the download and opening of the attachment, and this leaves the victim less time to realize that the attachment is suspicious and should not be run.\n",
      "\n",
      "Despite these advantages, the actors still have to grapple with the appearance of the executable. The actors tried but failed to completely hide the attachment’s type: a PE32 portable executable. They tried to mask the executable as a PDF, and Windows’ default configuration for hiding file extensions helped, but that was not enough.\n",
      "\n",
      "As already mentioned, NSIS comes with a scripting language that allows the clients to define many aspects of the installation procedure. To generate an installer for their application, the actors collect all necessary files, write an [NSIS].nsi script, and let NSIS interpret it. The output of the interpretation process is the actual installer for the application.\n",
      "\n",
      "We extracted the [NISIS].nsi script from Invoice·pdf.exe. Although most of the extract is junk code, two parts are useful. The first part lies at the very beginning of the script, where the Lempel Ziv Markov chain compression Algorithm (LZMA) is set for the files included in the installation bundle. The second relevant part of the script pertains to the overriding of the .onGUIInit callback.\n",
      "\n",
      "NSIS defines several callback functions that clients can overwrite to customize some aspects of the installation process. One of those functions is .onGUIInit, which is called every time the installer is launched to initialize the graphical user interface (GUI). In this particular case, the actor overwrote the .onGUIInit function to implement a behavior that had nothing to do with GUI settings. The function helps understand which files belong to the installation bundle: the Loader and the Encrypted Lokibot. We know this because their names are arguments of two consecutive calls to the File command, which is responsible for extracting files. The installer drops those files into the temp directory as a consequence of the InstallDir $TEMP directive.\n",
      "\n",
      "After dropping the files, the installer allocates a memory buffer of 46611 bytes by invoking the Alloc API exposed by the system library. The purpose of this buffer becomes clear after we look at the following three calls to the kernel32 library’s APIs:\n",
      "\n",
      "- CreateFile is called to open the Loader file. It opens the file with the desired access GENERIC_READ, and it stores the resulting file handle in the r10 register.\n",
      "- VirtualProtect is called to set the protection option PAGE_EXECUTE_READWRITE to the previously allocated memory buffer.\n",
      "- ReadFile is invoked to move the Loader file’s contents into the buffer, because its first argument is the r10 registry storing that file handle and because the destination buffer is held by the r4 register. Indeed, the size of the Loader file is exactly the same as that of the allocated buffer.\n",
      "\n",
      "The last relevant part of .onGUIInit deals with the invocation of whatever has just been read from the file. That invocation happens by jumping to the address stored in the r4 register and by invoking System::Call::$4(). Therefore, we can conclude that Invoice·pdf.exe acts as a dropper and launcher for the subsequent stages of the attack vector. In the next section, we discuss the content of the Loader file.\n",
      "\n",
      "### 5. The Loader\n",
      "\n",
      "We know that the NSIS installer drops the cgttxpglckz file into the temp directory; because the file name appears to be randomly generated, we call this file the Loader. We also know that the same installer loads the Loader into memory, asks for execution privileges for the memory page where it has been loaded, and eventually tries to execute the content. In this section, we clarify the role of the Loader in the attack chain.\n",
      "\n",
      "```python\n",
      "def decrypt(encrypted_buffer: bytearray) -> bytearray:\n",
      "    decrypted_buffer = []\n",
      "    for encrypted_byte in encrypted_buffer:\n",
      "        decrypted_byte = encrypted_byte\n",
      "        decrypted_byte -= 1\n",
      "        decrypted_byte ^= 0x5a\n",
      "        decrypted_byte += 0xc1\n",
      "        decrypted_byte -= 1\n",
      "        decrypted_byte -= 0xd\n",
      "        decrypted_byte += 0x31\n",
      "        decrypted_byte ^= 0x18\n",
      "        decrypted_byte += 0xf\n",
      "        decrypted_byte -= 0x2f\n",
      "        decrypted_byte ^= 0xcd\n",
      "        decrypted_byte ^= 0x4a\n",
      "        decrypted_byte += 1\n",
      "        decrypted_byte -= 0x2f\n",
      "        decrypted_byte ^= 0xb1\n",
      "        decrypted_byte ^= 0x48\n",
      "        decrypted_byte += 0x72\n",
      "        decrypted_byte -= 3\n",
      "        decrypted_byte -= 0x46\n",
      "        decrypted_byte += 0x77\n",
      "        decrypted_byte += 0xe5\n",
      "        decrypted_buffer.append(decrypted_byte & 0xff)\n",
      "    return bytearray(decrypted_buffer)\n",
      "```\n",
      "\n",
      "The file contains binary data that consists of the shellcode for x86 processors. The original shellcode has three relevant parts, which do the following:\n",
      "\n",
      "1. Load a byte array of 6685 integers into memory.\n",
      "2. Scan that array and apply a composite transformation to each of its elements. This transformation—based on XOR, addition, subtraction, decrement, and increment operations—has the goal of decrypting a shellcode payload. We have reverse-engineered the decryption function and propose a Python translation in the code snippet above.\n",
      "3. Jump to the newly decrypted payload.\n",
      "\n",
      "The decrypted payload contains shellcode for x86 processors. One of the functions initially called by the payload retrieves the memory address of the kernel32 library. Here is that function’s entire code:\n",
      "\n",
      "```\n",
      "000016c4 55              PUSH       EBP\n",
      "000016c5 8b ec           MOV        EBP, ESP\n",
      "; After this instruction, EAX contains the address of the _PEB (Process Environment Block) structure for the current process.\n",
      "000016c7 64 a1 30                 MOV        EAX, FS:[       0x30]\n",
      "; After this instruction, EAX contains the address of the  _PEB_LDR_DATA structure.\n",
      "000016cd 8b 40 0c        MOV        EAX, dword ptr [EAX + 0xc]\n",
      "; After this instruction, EAX contains the address of InLoadOrderModuleList. This double-linked list contains the loaded modules for the current process.\n",
      "000016d0 8b 40 0c        MOV        EAX, dword ptr [EAX + 0xc]\n",
      "000016d3 8b 00           MOV        EAX, dword ptr [EAX]\n",
      "000016d5 8b 00           MOV        EAX, dword ptr [EAX]\n",
      "; After this instruction, EAX contains the base address of the first module loaded by the current process.\n",
      "000016d7 8b 40 18                MOV        EAX, dword ptr [EAX +           0x18]; The first module loaded by any process is always kernel32.dll.\n",
      "000016d7 8b 40 18        MOV        EAX, dword ptr [EAX + 0x18]\n",
      "000016da 5d              POP        EBP\n",
      "000016db c3              RET\n",
      "```\n",
      "\n",
      "Essentially, the function finds the library address via the Process Environment Block (PEB) structure for the currently running process. Upon accessing the PEB structure, the function finds the list of loaded modules via the _PEB_LDR_DATA structure. Indeed, the kernel32 library is the first element within the InLoadOrderModuleList field of that structure: a double-linked list of loaded modules sorted by loading order. Once the payload has retrieved the library’s location, it looks for the address of several exported functions. To start iterating over all the names exported by the library, which are retrieved by parsing the PE header, the export resolution algorithm requires the library base address (in this case kernel32) and a numerical hash. For each exported name, the resolution algorithm computes a hash by using a custom hashing function. If the computed hash is equal to the hash provided to the export-resolution algorithm, then it retrieves the memory address for that export from the PE header and eventually returns it to the caller.\n",
      "\n",
      "The following code snippet shows a Python equivalent of the resolution algorithm that we reverse-engineered:\n",
      "\n",
      "```python\n",
      "def resolve_export(library_base_address: int, name_hash: int) -> int:\n",
      "    # The memory location of the pe_header structure\n",
      "    pe_header = library_base_address + 0x3c\n",
      "    # The memory location of exports_table\n",
      "    exports_table = pe_header + 0x78\n",
      "    # The memory location of the library export names\n",
      "    # An array of char pointers (null-terminated strings)\n",
      "    names = exports_table + 0x20\n",
      "    # The memory location of the library export addresses\n",
      "    # An array of Relative Virtual Addresses (RAVs)\n",
      "    addresses = export_table + 0x1c\n",
      "    i = 0\n",
      "    while True:\n",
      "        # The memory location of the number of export names included in the export table\n",
      "        names_size = exports_table + 0x18\n",
      "        if i >= names_size:\n",
      "            return 0\n",
      "        # A call to the custom hash function\n",
      "        candidate_name_hash = hash_name(names[i])\n",
      "        if candidate_name_hash == name_hash:\n",
      "            return addresses[i]\n",
      "        i += 1\n",
      "    return 0\n",
      "```\n",
      "\n",
      "The following code snippet shows a Python equivalent of the custom hashing function implemented in the payload. API hashing is an anti-analysis technique used by malware developers to hide the detail about which library exports are invoked in the code.\n",
      "\n",
      "```python\n",
      "def hash_name(name: str) -> int:\n",
      "    name_hash = 0x2326\n",
      "    for c in name:\n",
      "        current_hash = name_hash\n",
      "        current_hash <<= 0x5\n",
      "        current_hash += name_hash\n",
      "        current_hash += ord(c)\n",
      "        name_hash = current_hash & 0xffffffff\n",
      "    return name_hash\n",
      "```\n",
      "\n",
      "To better understand functionality, we de-hashed the function calls that occur on the payload. From that analysis, we concluded that the payload’s behavior can be summarized in three stages:\n",
      "\n",
      "1. The payload loads the Encrypted Lokibot file into memory. This file is dropped by the NSIS installer into the temp directory.\n",
      "2. The payload decrypts this file, which turns out to be a Lokibot executable.\n",
      "3. The payload spawns a new process, injects the executable into its memory space, and starts it.\n",
      "\n",
      "### 6. Encrypted Lokibot\n",
      "\n",
      "We know that the NSIS Installer drops file a01jkkyi4ridof2orcun into the temp directory. We also know that the Loader loads a01jkkyi4ridof2orcun into memory and decrypts it. This section focuses on a01jkkyi4ridof2orcun, which we have dubbed Encrypted Lokibot, and on the procedure used to decrypt it. \n",
      "\n",
      "The file contains binary data without any evident meaning. However, after the decryption, Encrypted Lokibot will contain a well-formed portable executable for the Lokibot malware. Lokibot decryption is implemented in a dedicated function, which expects (1) a memory buffer that contains the entire file and (2) the first key, 81687d7815174c2ba54304545bc506aa, together with its size, 32 bits. Lokibot decrypts the file by updating the provided memory buffer byte by byte.\n",
      "\n",
      "1. The decryption function does the following: It initializes two buffers of 256 integers each. One of the buffers is a second key used for the decryption.\n",
      "2. It constructs the second key by starting from the two buffers allocated in the first step.\n",
      "3. It decrypts the file by looping over each byte of the Encrypted Lokibot file and applying a composite transformation that involves two XOR operations with elements of the two keys.\n",
      "\n",
      "We reverse-engineered and translated the entire function to Python code:\n",
      "\n",
      "```python\n",
      "def decrypt(payload: bytearray, key_1: bytearray, key_1_size: int) -> None:\n",
      "    k = 0\n",
      "    l = 0\n",
      "    key_2, buffer = [], []\n",
      "    # first loop: buffer initialization\n",
      "    i = 0\n",
      "    while i < 256:\n",
      "        key_2.append(i)\n",
      "        buffer.append(key_1[i % key_1_size])\n",
      "        i += 1\n",
      "    # second loop: construct the second key\n",
      "    i = 0\n",
      "    while i < 256:\n",
      "        k = (key_2[i] + k + buffer[i]) & 0x800000ff\n",
      "        if k < 0:\n",
      "            k = ((k - 1) | 0xffffff00) + 1\n",
      "        temp = key_2[k]\n",
      "        key_2[k] = key_2[i]\n",
      "        key_2[i] = temp\n",
      "        i += 1\n",
      "    # third loop: decrypt the payload\n",
      "    k = 0\n",
      "    j = 0\n",
      "    while j < 106496:\n",
      "        i = (i + 1) & 0x800000ff\n",
      "        if i < 0:\n",
      "            i = ((i - 1) | 0xffffff00) + 1\n",
      "        k = (key_2[i] + k) & 0x800000ff\n",
      "        if k < 0:\n",
      "            k = ((k - 1) | 0xffffff00) + 1\n",
      "        temp = key_2[k]\n",
      "        key_2[k] = key_2[i]\n",
      "        key_2[i] = temp\n",
      "        l = (key_2[i] + key_2[k]) & 0x800000ff\n",
      "        if l < 0:\n",
      "            l = ((l - 1) | 0xffffff00) + 1\n",
      "        payload[j] ^= key_1[j % key_1_size]\n",
      "        payload[j] ^= key_2[l]\n",
      "        j += 1\n",
      "    return\n",
      "```\n",
      "\n",
      "### 7. Lokibot\n",
      "\n",
      "The fourth artifact is the final payload of the attack chain and is a 32-bit portable executable (PE32) compatible with 32-bit as well as 64-bit Microsoft Windows operating systems. As stated earlier, the unencrypted form of this executable is never saved in the file system; only its encrypted form, the Encrypted Lokibot file, is saved in the file system. This section analyzes this executable.\n",
      "\n",
      "The presence of a Rich Header suggests that PE32 has been developed in Visual Studio. The Rich Header section contains information about the build and the compilation suite. This information is stored as an XOR-encrypted array of elements, each referring to a specific product within the Visual Studio suite. In the case of Lokibot, the Rich Header reveals that the following tools are used:\n",
      "\n",
      "| Product | Build |\n",
      "|---------|-------|\n",
      "| Utc1500_C | Visual Studio 2008 |\n",
      "| Implib710 | Visual Studio 2003 |\n",
      "| Masm710 | Visual Studio 2003 |\n",
      "| Utc1800_LTCG_CPP | Visual Studio 2013 |\n",
      "| Import (old) | Visual Studio |\n",
      "| Masm900 | Visual Studio 2008 |\n",
      "| Import | Visual Studio |\n",
      "| Implib900 | Visual Studio 2008 |\n",
      "| Utc1800_CPP | Visual Studio 2013 |\n",
      "| Linker1200 | Visual Studio 2013 |\n",
      "\n",
      "This suggests that the artifact has been coded in C++. The building suite seems to date no earlier than 2013, and the compilation timestamp dates back to June 23, 2016, 16:04:21 UTC. Although the builders might have tampered with the meta information, it is possible the sample was built many years ago and is still being distributed.\n",
      "\n",
      "The overall and per-section levels of entropy are not high enough to suggest the presence of packed code:\n",
      "\n",
      "| Section | Entropy |\n",
      "|---------|---------|\n",
      "| Overall entropy | 6.053856 |\n",
      "| Section “.text” entropy | 6.492048 |\n",
      "| Section “.rdata” entropy | 4.255999 |\n",
      "| Section “.data” entropy | 0.321716 |\n",
      "| Section “.x” entropy | 0.209392 |\n",
      "\n",
      "However, the Import Table and Import Address Table (IAT) are small and that may indicate the intention of protecting the executable from static analysis techniques. The Import Table contains only four libraries (ws2_32.dll, kernel32.dll, ole32.dll, and oleaut32.dll), and the IAT contains only the following 19 calls:\n",
      "\n",
      "| Call | DLL |\n",
      "|------|-----|\n",
      "| getaddrinfo | ws2_32.dll |\n",
      "| freeaddrinfo | ws2_32.dll |\n",
      "| closesocket | ws2_32.dll |\n",
      "| WSAStartup | ws2_32.dll |\n",
      "| socket | ws2_32.dll |\n",
      "| send | ws2_32.dll |\n",
      "| recv | ws2_32.dll |\n",
      "| connect | ws2_32.dll |\n",
      "| GetProcessHeap | kernel32.dll |\n",
      "| HeapFree | kernel32.dll |\n",
      "| HeapAlloc | kernel32.dll |\n",
      "| SetLastError | kernel32.dll |\n",
      "| GetLastError | kernel32.dll |\n",
      "| CoCreateInstance | ole32.dll |\n",
      "| CoInitialize | ole32.dll |\n",
      "| CoUninitialize | ole32.dll |\n",
      "| VariantInit | oleaut32.dll |\n",
      "| SysFreeString | oleaut32.dll |\n",
      "| SysAllocString | oleaut32.dll |\n",
      "\n",
      "The calls included in the ws2_32.dll library are particularly interesting because they are invoked by Lokibot to implement a socket-based C&C communication channel.\n",
      "\n",
      "#### 7.1. Attribution via section .x\n",
      "\n",
      "A characteristic of this sample is section label .x: an unusual but well-known signature for Lokibot. Section .x is exactly 8 KB in size and contains the encrypted C&C URL as well as the code responsible for its decryption. The URL decryption algorithm consists of a bytewise XOR with the 0xFF key:\n",
      "\n",
      "```\n",
      "004a0016 bb ff ff        MOV        EBX, 0xdddfffff\n",
      "004a001b be 74 00        MOV        ESI, XORED_C2_URL\n",
      "004a0020 90              NOP\n",
      "004a0021 90              NOP\n",
      "004a0022 90              NOP\n",
      "004a0023 90              NOP\n",
      "LAB_004a0024                                    XREF[1]:     004a002e(j)\n",
      "004a0024 30 1e           XOR        byte ptr [ESI]=>XORED_C2_URL, BL\n",
      "004a0026 46              INC        ESI\n",
      "004a0027 90              NOP\n",
      "004a0028 90              NOP\n",
      "004a0029 90              NOP\n",
      "004a002a 90              NOP\n",
      "004a002b 80 3e 00        CMP        byte ptr [ESI]=>STRING_TERMINATOR, 0x0\n",
      "004a002e 75 f4           JNZ        LAB_004a0024\n",
      "```\n",
      "\n",
      "The C&C URL for the analyzed sample is stored from offset 0x18074 to offset 0x1809C. We were able to extract and decrypt it, to produce hxxp://173[.]208[.]204[.]37/k[.]php/SczbkxCQZQyVr. The section’s uncommon name, consistent size across the years, and the C&C URL encryption based on a 0xFF XOR-ring key, compelled us to develop a YARA rule:\n",
      "\n",
      "```yara\n",
      "rule lokibot {\n",
      "    meta:\n",
      "        description = \"Lokibot detection rule based on .x section and C&C decoding\"\n",
      "        author = \"gpellegrino@infoblox.com\"\n",
      "    strings:\n",
      "        $c2decoding = {BB FF FF DF DD BE 74 00 4A 00 90 90 90 90 30 1E}\n",
      "    condition:\n",
      "        uint16(0) == 0x5A4D\n",
      "        and filesize < 105KB\n",
      "        and uint16(0x260) == 0x782E\n",
      "        and uint16(0x270) == 0x2000\n",
      "        and $c2decoding in (uint32(0x274)..uint32(0x274)+0x2000)\n",
      "}\n",
      "```\n",
      "\n",
      "Thanks to that rule, we discovered that 62 additional samples were submitted on VirusTotal from April 2021 to early July 2021.\n",
      "\n",
      "#### 7.2. Heaven’s Gate\n",
      "\n",
      "The malware implements the well-known Heaven's Gate technique to evade antivirus detection on Windows systems older than Windows 10. Heaven’s Gate was first reported by Biv in 2009 and has since been discussed by various researchers. Since the introduction of the 64-bit versions of Windows XP, a 32-bit process can run in native 64-bit systems thanks to the WoW64 subsystem: a virtualized 32-bit environment running inside a 64-bit operating system. WoW64 executes a 32-bit process in a sandbox and isolates it from the outer 64-bit environment. However, Heaven’s Gate allows for a process to escape the WoW64 sandbox and lets it execute native 64-bit code. A malware would try to escape the WoW64 subsystem because antivirus software might not hook calls to 64-bit libraries that are made from 32-bit processes.\n",
      "\n",
      "The code snippet below shows one of the four instances of the Heaven’s Gate technique we observed in the sample under analysis. In the sample, segment 0x33 is pushed onto the stack first, and then the address where the x64 code resides. The RETF (return far) instruction makes use of the pushed values to direct the execution out of the x86 sandbox of the running process.\n",
      "\n",
      "```\n",
      "004072fa 6a 33           PUSH       0x33 ; x64 segment selector\n",
      "004072fc e8 00 00        CALL       $ + 5 ; pushes address 0x407301 on the stack\n",
      "00407301 83 04 24 05     ADD        [ESP + 0x48 + var_48], 5 ; sets the address to 0x00407306\n",
      "00407305 cb              RETF ; jump to the x64 code starting at 0x00407306\n",
      "...\n",
      "...\n",
      "00407358 e8 00 00        CALL       $ + 5 ; pushes address 0x0040735D on the stack\n",
      "0040735d c7 44 24        MOV        dword ptr [ESP + 0x4], 0x23 ; x86 segment selector\n",
      "00407365 83 04 24 0d     ADD        dword ptr [ESP], 0xd ; sets the address to 0x0040736A\n",
      "00407369 cb              RETF ; jump to x86 code starting at 0x0040736A\n",
      "```\n",
      "\n",
      "Heaven’s Gate is effective only on versions of Windows that preceded Windows 10. Windows 10 introduced the so-called Control Flow Guard feature, which enforces compilation as well as runtime controls, some of them addressing the Heaven's Gate, on any indirect call. This might strengthen the hypothesis that the executable is old. Another possibility is that those code regions were copied from some older codebase.\n",
      "\n",
      "#### 7.3. API hashing\n",
      "\n",
      "Because malware analysis takes time, the reverse-engineering efforts must be limited to small portions of malware code. Selecting the right parts of code and omitting irrelevant ones saves time and resources for truly impactful activities: persistence setting, exploitation, and analyzing the parts of code that expose relevant functionalities of malware. A common way to quickly understand what a portion of code does is to check which API functions it invokes. Unfortunately, the anti-analysis technique of API hashing can hinder this process by obfuscating API function calls mentioned in the code. The code snippet below is an example of the Lokibot API hashing technique:\n",
      "\n",
      "```\n",
      "00405eff 55              PUSH       EBP\n",
      "00405f00 8b ec           MOV        EBP, ESP\n",
      "00405f02 5d              POP        EBP\n",
      "00405f03 e9 1c fa        JMP        LAB_00405924\n",
      "...\n",
      "...\n",
      "LAB_00405924\n",
      "00405924 55              PUSH       EBP\n",
      "00405925 8b ec           MOV        EBP, ESP\n",
      "00405927 6a 00           PUSH       0x0\n",
      "00405929 6a 00           PUSH       0x0\n",
      "0040592b 68 d4 5b        PUSH       0xd6865bd4 ; hash for the StrStrW API call\n",
      "00405930 6a 02           PUSH       0x2 ; DLL identifier for shlwapi.dll\n",
      "00405932 e8 ae d8        CALL       getApiByDllIdAndApiHash\n",
      "00405937 ff 75 0c        PUSH       dword ptr [EBP + param_2] ; second argument to StrStr\n",
      "0040593a ff 75 08        PUSH       dword ptr [EBP + param_1] ; first argument to StrStr\n",
      "0040593d ff d0           CALL       EAX ; implicit call to StrStrW\n",
      "0040593f 5d              POP        EBP\n",
      "00405940 c3              RET\n",
      "```\n",
      "\n",
      "The code invokes the StrStrW API function included in the shlwapi DLL, but there is no mention of this API call in the code. Instead, there is an invocation of function getApiByDllIdAndApiHash, which accepts four arguments, only the first two of which are meaningful:\n",
      "\n",
      "- the DLL identifier: 2 in the code snippet\n",
      "- the API hash: 0xd6865bd4 in the code snippet\n",
      "\n",
      "getApiByDllIdAndApiHash uses these arguments to find and return the address where StrStrW API has been loaded. This address is stored in the EAX register and called at the very end. To protect almost all API invocations made by the sample, this schema is replicated many times.\n",
      "\n",
      "API hashing schema consists of two steps:\n",
      "\n",
      "1. Obtain the memory address of a DLL, starting from a numerical DLL identifier.\n",
      "2. Use the obtained DLL address and a hash to obtain the memory address of the API function. This step starts if, and only if, step 1 was successful.\n",
      "\n",
      "We will discuss these two steps then the function for calculating a hash.\n",
      "\n",
      "##### 7.3.1. DLL resolution\n",
      "\n",
      "The first step of the API hashing schema consists of two special cases and a general case. The two special cases are handled the same way and refer to two specific DLLs: kernel32 with identifier 0, and ntdll with identifier 1. In both cases, the DLL identifier is associated with a hash specific to each DLL: 0xf96af9ce for kernel32, and 0xefd4f033 for ntdll. The hash is then passed to a function responsible for iterating through all loaded DLLs, extracting a DLL name, computing the hash of that name, and checking whether that hash matches the one provided to the function. If there is a match, the function returns the DLL memory address; otherwise, it returns NULL.\n",
      "\n",
      "The code snippet below shows how Lokibot gathers the relevant information, namely the DLL name and the DLL memory address, from the loaded modules. Lokibot parses the Process Environment Block (PEB) structure for the current process and then reaches _PEB_LDR_DATA_STRUCTURE, which contains the loaded DLLs. Within _PEB_LDR_DATA_STRUCTURE, the sample accesses InLoadOrderModuleList, which is a double-linked list that contains an element for each loaded DLL. The list is sorted by loading order.\n",
      "\n",
      "```\n",
      "00403187 64 a1 30                  MOV        EAX, FS:[        0x30] ; address of the _PEB structure\n",
      "0040318d 89 45 fc        MOV        dword ptr [EBP + local_8], EAX\n",
      "00403190 8b 45 fc        MOV        EAX, dword ptr [EBP + local_8]\n",
      "; address of the _PEB_LDR_DATA structure\n",
      "00403193 8b 40 0c        MOV        EAX, dword ptr [EAX + 0xc]\n",
      "; After this instruction, EAX contains the address of InLoadOrderModuleList.\n",
      "00403196 8b 58 0c        MOV        EBX, dword ptr [EAX + 0xc] ; address of the InLoadOrderModuleList\n",
      "00403199 8b f3           MOV        ESI, EBX\n",
      "LAB_0040319b ; start of the loop on the loaded DLLs\n",
      "; base address of the DLL (DllBase)\n",
      "0040319b 8b 46 18                  MOV        EAX, dword ptr [ESI +              0x18]\n",
      "; address of the full DLL name (FullDllName)\n",
      "0040319e ff 76 28                  PUSH         dword ptr [ESI +          0x28]\n",
      "...\n",
      "...\n",
      "```\n",
      "\n",
      "Kernel32 and ntdll will both be in this list, for any process, because these libraries include fundamental APIs for executing any program. Each element in InLoadOrderModuleList is of type _LDR_DATA_TABLE_ENTRY and contains, among many fields, the DLL address DllBase and the full name of DLL, FullDllName, which is the path to the DLL on disk. The code snippet below shows the first part of _LDR_DATA_TABLE_ENTRY as it is defined in the ntdll library:\n",
      "\n",
      "```\n",
      "_LDR_DATA_TABLE_ENTRY\n",
      "    +0x000 InLoadOrderLinks : _LIST_ENTRY\n",
      "    +0x008 InMemoryOrderLinks : _LIST_ENTRY\n",
      "    +0x010 InInitializationOrderLinks : _LIST_ENTRY\n",
      "    +0x018 DllBase          : Ptr32 Void\n",
      "    +0x01c EntryPoint       : Ptr32 Void\n",
      "    +0x020 SizeOfImage      : Uint4B\n",
      "    +0x024 FullDllName      : _UNICODE_STRING\n",
      "    +0x02c BaseDllName      : _UNICODE_STRING\n",
      "    +0x034 FlagGroup        : [4] UChar\n",
      "```\n",
      "\n",
      "The DllBase field is located at offset 0x18. The FullDllName field is located at offset 0x24, which appears to be unaligned with the offset accessed by the malware, 0x28. However, we need to consider that FullDllName is of type _UNICODE_STRING: a structure that contains two additional integer fields before the actual string buffer, at relative offset 0x4. Therefore, when the malware tries to access offset 0x28 within _LDR_DATA_TABLE_ENTRY, it is actually trying to access the string buffer located four bytes after the starting address of FullDllName.\n",
      "\n",
      "The general case regards 11 additional DLLs whose API functions the malware will attempt to call. On all those occasions, the DLL identifier is not mapped to any hash but is, instead, mapped to an index of a memory buffer that contains the DLL names of those 11 DLLs. The DLL names are encoded in the UTF-16 little endian, and the buffer is filled every time the DLL resolution function is invoked. The code snippet shows the part of the buffer that contains the DLL names as they appear in the debugger.\n",
      "\n",
      "##### 7.3.2. API resolution\n",
      "\n",
      "In this step, the API hashing schema requires the address of a DLL and a hash to find the address of an API. The inner workings of the API resolution algorithm are similar to those of the algorithm used for the special cases of kernel32 and ntdll in the first step. That is, the function implemented in this step iterates through the table of DLL name pointers. The table is part of the PE export table that contains the array of the exported names. For each name in the table, the function computes the hash of the name and compares the result with the hash provided as an argument. If the two hashes match, the function returns the address of the matching export by calling the GetProcAddress API.\n",
      "\n",
      "GetProcAddress is not directly invoked, because it is hidden by the API hashing technique. Because GetProcAddress is exposed by the kernel32 library, the resolution falls into one of the special cases described at the beginning of section 7.3, API hashing. If the function cannot find any match for the provided hash, then it returns NULL. The following code snippet clarifies how the API resolution function gathers API names:\n",
      "\n",
      "```\n",
      "004030d2 8b 7d 08                   MOV        EDI, dword ptr [EBP + param_1]                    ; DLL’s base address\n",
      "004030d5 33 db           XOR        EBX, EBX\n",
      "004030d7 c1 e8 10                   SHR        EAX,        0x10\n",
      "004030da 8b 57 3c        MOV        EDX, dword ptr [EDI + 0x3c] ; start of the PE header\n",
      "004030dd 89 55 f4                MOV        dword ptr [EBP + local_10], EDX\n",
      "; The following instruction computes the offset of the export table in the PE header\n",
      "004030e0 8b 74 3a 78     MOV        ESI, dword ptr [EDX + EDI*0x1 + 0x78]\n",
      "; The following instruction computes the address of the export table\n",
      "004030e4 03 f7           ADD        ESI, EDI\n",
      "...\n",
      "...\n",
      "; The following instruction computes the offset of the AddressOfNames field in the export table\n",
      "004030f3 8b 4e 20                MOV        ECX, dword ptr [ESI +            0x20]\n",
      "004030f6 8b 46 24                MOV        EAX, dword ptr [ESI +            0x24]\n",
      "; The following instruction computes the address of the AddressOfNames field in the export table\n",
      "004030f9 03 cf           ADD        ECX, EDI\n",
      "```\n",
      "\n",
      "In the code above, the EDI register holds the DLL address as it was passed to the API resolution function. The EDX register holds the information placed at offset 0x3c from the DLL base address; that offset is where the PE header starts. The ESI register holds the offset coming out of the summation of the PE header, the DLL base address, and 0x78. Because 0x78 is the offset of the export table, the ESI register will contain the offset to that table, starting from the beginning of the DLL. After the summation between the contents of the ESI and EDI registers, ESI will hold the memory address of the export table. Because offset 0x20 within the export table points to the AddressOfNames array, the summation between the ECX and EDI registers at the last line will produce the address of that array. As already mentioned, this array will get scanned to fetch the names of all API functions exported by the DLL.\n",
      "\n",
      "##### 7.3.3. The hash function\n",
      "\n",
      "```python\n",
      "def custom_hash(name: str, length: int) -> int:\n",
      "    name_hash = 0xffffffff\n",
      "    i = 0\n",
      "    while length != 0:\n",
      "        length -= 1\n",
      "        name_hash ^= ord(name[i])\n",
      "        i += 1\n",
      "        j = 8\n",
      "        while True:\n",
      "            if (name_hash & 0xff) & 1:\n",
      "                name_hash ^= 0x4358ad54\n",
      "            name_hash >>= 1\n",
      "            j -= 1\n",
      "            if j == 0:\n",
      "                break\n",
      "    return ~name_hash & 0xffffffff\n",
      "```\n",
      "\n",
      "Both stages of the API hashing schema rely on the same custom hashing function to compute DLL names and hashes of API function names at runtime. We reverse-engineered and converted the hashing function into Python code. Although the hashing function does not vary, there is some difference in how it is used within the two steps of the process. As the code snippet shows, the number of iterations of the outer loop depends on what we call the length argument. When the DLL name is being hashed, in the special case of kernel32 and ntdll, the provided length argument is doubled. The reason for this lies in how those DLL names are encoded in memory. Because kernel32 and ntdll names are encoded in UTF16 little endian, the characters in those strings are padded with NULL (0x00) symbols. Therefore, the length argument is set to two times the string length. The same does not hold for the API calls; as shown in the following sample taken at debugging time, these calls are encoded in UTF-8.\n",
      "\n",
      "#### 7.4. A vaccine against Lokibot\n",
      "\n",
      "One of Lokibot’s very first moves is to check for the existence of a specific mutex. If this mutex already exists, then Lokibot quits immediately, to avoid having multiple instances of the malware running on the same system. This check is implemented in two consecutive steps:\n",
      "\n",
      "1. Lokibot invokes the CreateMutexW API, exposed by kernel32.\n",
      "2. Lokibot invokes the GetLastError API to determine whether an error of type ERROR_ALREADY_EXISTS was raised.\n",
      "\n",
      "The implementation of this behavior is reported in the code snippet below. The 0xb7 value, checked at the end of the snippet, corresponds to the ERROR_ALREADY_EXISTS error, which indeed is raised by CreateMutexW whenever the requested mutex already exists:\n",
      "\n",
      "```\n",
      "00413982 e8 10 04        CALL       getMutexLabel\n",
      "00413987 53              PUSH       EBX\n",
      "00413988 53              PUSH       EBX\n",
      "00413989 68 f4 7d        PUSH       0xcf167df4 ; hash for CreateMutexW\n",
      "0041398e 53              PUSH       EBX\n",
      "0041398f 8b f0           MOV        ESI, EAX\n",
      "; API-hashing protection for CreateMutexW\n",
      "00413991 e8 4f f8        CALL       getApiByDllIdAndHash\n",
      "00413996 56              PUSH       ESI\n",
      "00413997 33 f6           XOR        ESI, ESI\n",
      "00413999 46              INC        ESI\n",
      "0041399a 56              PUSH       ESI\n",
      "0041399b 53              PUSH       EBX\n",
      "0041399c ff d0           CALL       EAX\n",
      "0041399e ff 15 10        CALL       dword ptr [->KERNEL32.DLL::GetLastError]\n",
      "; check whether the error code is ERROR_ALREADY_EXISTS (0xb7)\n",
      "004139a4 3d b7 00        CMP        EAX, 0xb7\n",
      "004139a9 75 07           JNZ        LAB_004139b2\n",
      "004139ab 53              PUSH       EBX\n",
      "004139ac e8 d0 01        CALL       exitProcess\n",
      "004139b1 59              POP        ECX\n",
      "```\n",
      "\n",
      "The mutex label requested by Lokibot is generated by the function we refer to as getMutexLabel. This function is deterministic in its way of generating the mutex label starting from the machine GUID. The machine GUID is a string created by Windows at installation time and is unique for each machine. The machine GUID has the following format: XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX where X is a hex digit. The GUID is stored as a value for the SOFTWARE\\Microsoft\\Cryptography\\MachineGuid registry key.\n",
      "\n",
      "After extracting the machine GUID by calling APIs RegOpenKeyExA and RegQueryValueExA, Lokibot computes its MD5 hash by calling APIs CryptAcquireContextW, CryptCreateHash, and CryptGetHashParam, which are exposed by DLL ADVAPI32 and protected by the API-hashing technique discussed earlier. We know that the end goal is to obtain the MD5 hash, because CryptCreateHash is invoked with the CALG_MD5 constant as the Algid argument. Here is a code snippet for CryptCreateHash:\n",
      "\n",
      "```\n",
      "; the invocation of CryptCreateHash API is protected by the API hashing technique described in section 7.3, API hashing\n",
      "004038c0 e8 20 f9        CALL       getApiByDllIdAndHash\n",
      "004038c5 8d 4d fc        LEA        ECX=>local_8, [EBP + -0x4]\n",
      "004038c8 51              PUSH       ECX\n",
      "004038c9 6a 00           PUSH       0x0\n",
      "004038cb 6a 00           PUSH       0x0\n",
      "004038cd 68 03 80        PUSH       0x8003 ; CALG_MD5 Algid argument\n",
      "004038d2 56              PUSH       ESI\n",
      "004038d3 ff d0           CALL       EAX ; a call to CryptCreateHash\n",
      "```\n",
      "\n",
      "MD5 of the machine GUID is manipulated by upper-casing all its characters, encoding it in UTF8, and truncating it at the 24th character. Encoding is accomplished by invoking the function MultiByteToWideChar, which is exposed by kernel32 DLL. For example, assume the GUID for a hypothetical machine is b8400c54-53cb-4b8d-ae87-eeb55841773a. The MD5 hash of that GUID is 9efd2ea6da53da851313f31cd3db8399; after applying the transformations, the hash is converted into string 9EFD2EA6DA53DA851313F31C and will be the label for the mutex that this variant of Lokibot will check on the hypothetical machine.\n",
      "\n",
      "Because the mutex label is computed deterministically, we can create it after we determine a machine GUID. Moreover, we can create the mutex before Lokibot runs on a particular machine! That will automatically protect the machine against the threat posed by this malware. Indeed, when Lokibot runs on a machine and tries to create the mutex, it will catch ERROR_ALREADY_EXISTS and eventually terminate the execution.\n",
      "\n",
      "To demonstrate this line of defense, we developed a Proof of Concept (PoC) called Lokibot Vaccine. Lokibot Vaccine reads the machine GUID and creates the mutex label by following the process used by Lokibot. Furthermore, Lokibot Vaccine tries to push the mutex by calling CreateMutex. If it finds that the mutex has already been set by another process, then it will conclude that a Lokibot sample is already running on the system; otherwise, it will create the mutex. From that moment onward, potential Lokibot samples that use the mutex as an infection marker will have no chance to expose their malicious behavior.\n",
      "\n",
      "### 7.5. The failed persistence\n",
      "\n",
      "Persistence denotes the actions that enable a piece of malware to run again after the system reboots. This Lokibot variant tries to set persistence by following a series of stages, but it fails. The analysis of this failure provides support for the hypothesis of Lokibot being edited by a second actor who had no access to the original source code.\n",
      "\n",
      "Lokibot attempts to set persistence by:\n",
      "\n",
      "1. Generating the persistence directory’s name.\n",
      "2. Creating the persistence directory.\n",
      "3. Moving the Lokibot executable into the persistence directory.\n",
      "4. Renaming the executable.\n",
      "5. Decrypting the registry-based persistence subkey (RunKey).\n",
      "6. Setting the subkey to the path of the Lokibot executable.\n",
      "7. Altering both the Lokibot executable and the persistence directory attributes to hide them and make them more difficult to remove.\n",
      "\n",
      "We will now go through these stages in more detail. Lokibot moves, creates, and maintains three files during its execution:\n",
      "\n",
      "- a database that contains the hashes of all exfiltrated bundles of files.\n",
      "- a lock (.lck) file created to prevent concurrent access to shared resources.\n",
      "- the Lokibot executable moved when persistence is being set.\n",
      "\n",
      "All three files are located in a directory that we call the persistence directory. Lokibot creates it as a subdirectory of %APPDATA%, whose address it obtains by calling API SHGetFolderPathW, which is exposed by the SHELL32 library. SHGetFolderPathW is a deprecated API used to give access to many standard Windows directories, each uniquely identified by the corresponding CSIDL constant. Lokibot calls SHGetFolderPathW with the CSIDL argument set to 0x1a, which corresponds to %APPDATA%.</s>\n",
      "=========================\n",
      "To maintain persistence\t the attacker created scheduled tasks on compromised systems that would re-execute the ShadowPuppet backdoor every 6 hours. Additionally\t a malicious service was installed that would restart the backdoor if it was terminated. The threat actor established persistence through two main mechanisms: 1) Creating scheduled tasks on compromised systems to re-execute the ShadowPuppet backdoor every 6 hours\t and 2) Installing a malicious service that would restart the backdoor if it was terminated.</s>\n",
      "=========================\n",
      "# Using Similarity to Expand Context and Map Out Threat Campaigns\n",
      "\n",
      "**TL;DR:** VirusTotal allows you to search for similar files according to different orthogonal notions (structure, visual layout, icons, execution behavior, etc.). File similarity can be combined with the “have:” search modifier to gain more context about threats, such as the emails or URLs that distribute them.\n",
      "\n",
      "This is the second blog post in our similarity series. The first article focused on how to trigger file similarity searches and the different similarity vectors at your disposal. In this series, we have also conducted a webinar that can be viewed on-demand, focusing on using similarity to automatically produce optimal YARA rules to detect a given malware framework/family/campaign via VTDIFF.\n",
      "\n",
      "As a SOC analyst or Incident Responder, you are often confronted with files you know nothing about. Your SIEM describes their internal sightings and actions but fails to transmit the bigger picture. You are constrained by the narrow visibility of your corporate logs. Context is king, and the problem is that you are fighting threat actors that operate globally with just a piece of the puzzle—your local data.\n",
      "\n",
      "What is this file? Who is behind it? What is their modus operandi? How did it get there? Are there other related components? What does it do? Are there other variants that could have impacted my organization in the past? Any that could impact us in the future? How do I contain it? Your SIEM, case management system, EDR, firewall, IDS, etc., don’t answer these questions. You are missing a necessary layer in your defense-in-depth security strategy.\n",
      "\n",
      "VirusTotal is your saving grace. You jump into VT ENTERPRISE and look up the hash: threat reputation is useful, but you need further context. Your task is to identify IoCs that can be used for remediation, such as blocking a command-and-control domain in the network perimeter, as well as artifacts that can be used for proactive threat hunting purposes to determine whether there has been a breach and what its scope is. The issue is that sometimes VirusTotal does not have full context for a specific individual file in terms of sandbox reports, in-the-wild sightings, relationships, etc., and so your investigation might end here.\n",
      "\n",
      "## How to Do It Better\n",
      "\n",
      "Isolated hashes are of limited value. Many times they are unique per victim or campaign, so a better idea would be finding the cluster/family/campaign they belong to in order to unearth remediation IoCs and threat hunting patterns. Most importantly, you need to leverage those groupings to surface command-and-control domains, drop zones, distribution URLs, phishing emails, etc., that can be used for mitigation and containment, and to build proper understanding and situational awareness.\n",
      "\n",
      "Similarity and the “have” search modifier to the rescue. Let’s imagine the initial hash that popped up as an alert in our environment was a first-stage EMOTET dropper, i.e., a document that delivers a malicious payload through macros. Threat reputation allows you to perform an immediate first assessment (alert triage), but other than that, there is little context in terms of remediation IoCs and hunting artifacts. We still know nothing about how this file gets distributed, i.e., its delivery vector. Similarly, we fully ignore whether this is something spear-phished exclusively against our organization or part of a larger campaign. What about the threat network infrastructure? Does it download additional payloads? Does it communicate with a command-and-control?\n",
      "\n",
      "The next step in an incident response engagement—and this is what most analysts fail to do—is to jump into the file’s cluster (its family/framework/campaign) to expand context and surface IoCs. This is just one click away.\n",
      "\n",
      "For documents, there is a limited number of approaches to find similar files (other file formats will expose more). This said, they are very rich because they are fully orthogonal: structural features, visual layout, local sensitive fuzzy hashing, execution behavior similarity. Let’s jump to other similar files based on the document’s visual layout by clicking on “Similar by icon/thumbnail” or on the thumbnail itself.\n",
      "\n",
      "There are too many matches; we would have to iterate over every single one to surface particular patterns that may allow us to understand the campaign.\n",
      "\n",
      "## Finding Phishing Emails That Distribute the Threat\n",
      "\n",
      "We can narrow down the search above to match exclusively those files that have been seen as an attachment in some email uploaded to VirusTotal:\n",
      "\n",
      "`main_icon_dhash:23232b2b00010000 AND have:email_parents`\n",
      "\n",
      "(Note that you can also use `tag:attachment` instead of `have:email_parents`.)\n",
      "\n",
      "We can now run through the matching files, open up their Relations tab, and jump into the pertinent email parent to understand the deception techniques being used in the campaign. This particular instance poses as some kind of World Health Organization report on COVID. It is important to inspect all the other emails because not only will they tell us more about the lures, but they will also allow us to identify targeted industries, geographical spread, activity time spans, etc. For instance, there could be other localized variants targeting some other corporate branches. Access to these emails will not only give us greater insight into the attacker, but it is also something we can leverage tactically to improve filtering in our email gateways.\n",
      "\n",
      "## Discovering URLs That Distribute This Threat\n",
      "\n",
      "We want to see if this campaign is also being distributed via download URLs. If that’s the case, we can block them in our network perimeter or use them to search across web proxy logs. Let’s ask VirusTotal whether any of the files in the cluster have associated in-the-wild URLs:\n",
      "\n",
      "`main_icon_dhash:23232b2b00010000 AND have:itw`\n",
      "\n",
      "We can now jump into the Relations tab to export these additional IoCs. There are over 3K files with in-the-wild URLs; note that we can automate all of this via the API.\n",
      "\n",
      "## Identifying Command-and-Control/Exfiltration Infrastructure\n",
      "\n",
      "The next step is to understand whether any of the machines in our corporate fleet are beaconing out to infrastructure tied to this campaign. At the same time, we will probably want to block the CnC and exfiltration points to mitigate the impact of historical undetected breaches. Let’s filter down the search to focus exclusively on those files that exhibited network communications when executed in a dynamic analysis sandbox:\n",
      "\n",
      "`main_icon_dhash:23232b2b00010000 AND have:behaviour_network`\n",
      "\n",
      "Most of the matching files have been analyzed by several sandboxes participating in our multi-sandbox effort. This gives us unparalleled visibility into the campaign. For an attacker, it is easy to evade a single sandbox; it is far more complex to do so for 17+ of them at the same time. Each one of them is set up in a different geographical region, going out to the internet through a different IP address, running different OS versions, with different software and language packages installed, etc. As a result, we now have very interesting sightings in terms of infrastructure.\n",
      "\n",
      "These communication points can be very easily triaged. Remember that VirusTotal also characterizes domains, IP addresses, and URLs. Threat reputation for these domains further confirms that they are accurate IoCs. The domain relationships (in-the-wild sightings) tell the same story.\n",
      "\n",
      "We now have additional IoCs that we can feed into our stack to proactively defend our organization from other variants. As a bonus point, pivoting to other campaign files that have sandbox behavior reports allows us to shed more light into other TTPs that we might be tracking via MITRE ATT&CK (e.g., installation, actions on objectives, etc.).\n",
      "\n",
      "## Gaining Context Through the Community\n",
      "\n",
      "Furthering the use of the “have” search modifier, we can also leverage it to find files on which some VT Community user has placed a comment providing more context:\n",
      "\n",
      "`main_icon_dhash:23232b2b00010000 AND have:comments`\n",
      "\n",
      "Community comments often give us interesting details in terms of in-the-wild observations, malware capabilities, reverse engineering reports, attribution, etc. For example, in this particular case, we learn about additional distribution URLs. This other case helps us understand that this first stage is EMOTET and allows us to jump into a pastebin dump with further context about the campaign in terms of related hashes and network infrastructure.\n",
      "\n",
      "## Additional Context\n",
      "\n",
      "The “have” modifier accepts many other values; some of the more representative ones are:\n",
      "\n",
      "- `compressed_parents`: the files were seen inside a compressed file uploaded to VirusTotal.\n",
      "- `pcap_parents`: the files were seen in a network traffic recording uploaded to VirusTotal.\n",
      "- `embedded_(urls/domains/ips)`: a URL/domain/IP address pattern was extracted from the binary bodies of the files.\n",
      "- `behaviour`: the files managed to execute in at least one sandbox and produced the pertinent dynamic analysis report.\n",
      "- `behaviour_registry`: the files executed in a sandbox and interacted with the Windows Registry.\n",
      "- `crowdsource_yara_rule`: the files match some YARA rule coming from open source community repositories; these rules often provide additional references and descriptions about a threat.\n",
      "\n",
      "## Summing Up\n",
      "\n",
      "VirusTotal aggregates orthogonal means to cluster together groups of related files. Files that may belong to the same malware family/framework/campaign/actor. These file similarity vectors range from structural features to dynamic analysis observations. \n",
      "\n",
      "We started off with a single IoC for which we had little context, neither did VirusTotal, beyond basic threat reputation. By leveraging file similarity, we managed to find thousands of other files related to the campaign/malware framework. Through the “have” search modifier, we then narrowed down our searches to identify phishing emails used by the attackers, distribution URLs, additional network infrastructure such as CnCs, and context shared by other threat researchers.\n",
      "\n",
      "All of this is tactical intelligence that can be fed into network perimeter defenses, but also context that can be operationalized and digested into TTPs to characterize threat actors. Finally, this blog post presented an incident response scenario, but the very same logic can be applied to threat actor tracking or campaign monitoring use cases.\n",
      "\n",
      "This post was authored by Emiliano Martinez.</s>\n",
      "Train dataset size: 8971\n",
      "Max length: 29902\n",
      "Eval dataset size: 3846\n",
      "Max length: 42783\n"
     ]
    }
   ],
   "source": [
    "for row in train_dataset[:3][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Max length:\", max([len(tokenizer.encode(row)) for row in train_dataset[\"text\"]]))\n",
    "print(\"Eval dataset size:\", len(eval_dataset))\n",
    "print(\"Max length:\", max([len(tokenizer.encode(row)) for row in eval_dataset[\"text\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsloth Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd22005230b24da08701b10a1b93fd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/2563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,563 | Num Epochs = 1 | Total steps = 320\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 25,231,360/4,000,000,000 (0.63% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 10:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.386900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.267800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.198600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.162700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.203900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.073600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('tinyllama-bnb-4bit-finetuned\\\\tokenizer_config.json',\n",
       " 'tinyllama-bnb-4bit-finetuned\\\\special_tokens_map.json',\n",
       " 'tinyllama-bnb-4bit-finetuned\\\\tokenizer.model',\n",
       " 'tinyllama-bnb-4bit-finetuned\\\\added_tokens.json',\n",
       " 'tinyllama-bnb-4bit-finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "from unsloth import is_bfloat16_supported, unsloth_train, UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=1,\n",
    "    packing=True,  # pack the dataset to fit into the context length\n",
    "    args=UnslothTrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        # per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,  # simulates larger batch size without increasing memory usage\n",
    "        warmup_ratio = 0.1,\n",
    "\n",
    "        num_train_epochs=1,  # default; anything more than 3 is not optimal\n",
    "        # max_steps=60,  # for full run comment this and use only num_train_epochs\n",
    "        learning_rate=2e-5,  # try 1e-4, 2e-5 or 5e-5\n",
    "        # embedding_learning_rate=2e-5,  # 2-10x smaller than learning rate\n",
    "\n",
    "        # eval_strategy=\"steps\",\n",
    "        # eval_steps=1,\n",
    "        logging_steps=10,\n",
    "        # save_steps=50,\n",
    "        # metric_for_best_model=\"eval_loss\",\n",
    "        # load_best_model_at_end=True,\n",
    "\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"results\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# trainer_stats = trainer.train()  # buggy gradient accumulation\n",
    "trainer_stats = unsloth_train(trainer)\n",
    "\n",
    "finetuned_model = f\"{model_name}-finetuned\"\n",
    "model.save_pretrained(finetuned_model)\n",
    "tokenizer.save_pretrained(finetuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=True, max_length=max_seq_length)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 8,971 | Num Epochs = 1 | Total steps = 140\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 32\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 32 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 25,231,360/4,000,000,000 (0.63% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 12:44:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.135600</td>\n",
       "      <td>2.200339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.140300</td>\n",
       "      <td>2.202069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.135600</td>\n",
       "      <td>2.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.173500</td>\n",
       "      <td>2.187443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.197500</td>\n",
       "      <td>2.181875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>2.177176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.171300</td>\n",
       "      <td>2.172313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.167100</td>\n",
       "      <td>2.168227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.166500</td>\n",
       "      <td>2.165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.151000</td>\n",
       "      <td>2.162195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.166800</td>\n",
       "      <td>2.159792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.155900</td>\n",
       "      <td>2.158715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.121700</td>\n",
       "      <td>2.157408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.156800</td>\n",
       "      <td>2.156634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tinyllama-bnb-4bit-finetuned-causal-2nd\\\\tokenizer_config.json',\n",
       " 'tinyllama-bnb-4bit-finetuned-causal-2nd\\\\special_tokens_map.json',\n",
       " 'tinyllama-bnb-4bit-finetuned-causal-2nd\\\\tokenizer.model',\n",
       " 'tinyllama-bnb-4bit-finetuned-causal-2nd\\\\added_tokens.json',\n",
       " 'tinyllama-bnb-4bit-finetuned-causal-2nd\\\\tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Causal Language Modeling for raw text\n",
    "from unsloth import is_bfloat16_supported\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # Causal LM\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=20)],\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=32,  # simulates larger batch size without increasing memory usage\n",
    "        warmup_ratio = 0.1,\n",
    "\n",
    "        num_train_epochs=1,  # default; anything more than 3 is not optimal\n",
    "        # max_steps=60,\n",
    "        learning_rate=2e-4,  # try 1e-4, 2e-5 or 5e-5\n",
    "        max_grad_norm=1.0,\n",
    "\n",
    "        logging_steps=10,\n",
    "        eval_steps=10,\n",
    "        eval_strategy=\"steps\",\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        load_best_model_at_end=True,\n",
    "\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"results_causal-2nd\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "finetuned_model = f\"{model_name}-finetuned-causal-2nd\"\n",
    "model.save_pretrained(finetuned_model)\n",
    "tokenizer.save_pretrained(finetuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "train_steps = [log[\"step\"] for log in logs if \"loss\" in log and \"eval_loss\" not in log]\n",
    "train_losses = [log[\"loss\"] for log in logs if \"loss\" in log and \"eval_loss\" not in log]\n",
    "\n",
    "eval_steps = [log[\"step\"] for log in logs if \"eval_loss\" in log]\n",
    "eval_losses = [log[\"eval_loss\"] for log in logs if \"eval_loss\" in log]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_steps, train_losses, label=\"Train Loss\", marker='o', linestyle='--')\n",
    "plt.plot(eval_steps, eval_losses, label=\"Eval Loss\", marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"train_eval_loss.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1923' max='1923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1923/1923 50:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 8.64199841335152\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# perplexity\n",
    "eval_results = trainer.evaluate()\n",
    "perplexity = math.exp(eval_results[\"eval_loss\"])\n",
    "print(f\"Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "# final_eval_loss = 2.156634\n",
    "# perplexity = math.exp(final_eval_loss)\n",
    "# print(f\"Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "# from evaluate import load \n",
    "# perplexity_huggingface = load(\"perplexity\", module_type=\"metric\")\n",
    "# perplexity = perplexity_huggingface.compute(model_id=model_name, predictions=eval_dataset[\"text\"])\n",
    "# print(f\"Perplexity: {perplexity['perplexity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.8: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5080. Num GPUs = 1. Max memory: 15.92 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: unsloth/tinyllama-bnb-4bit can only handle sequence lengths of at most 2048.\n",
      "But with kaiokendev's RoPE scaling of 2.0, it can be magically be extended to 4096!\n"
     ]
    }
   ],
   "source": [
    "# we can load the model from the checkpoint here\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=f\"{model_name}-finetuned-causal-2nd\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to be selected: 3846\n",
      "Finally selected samples: 2895\n",
      "==================================================\n",
      "Continuously hunt for signs of compromise or credential misuse, particularly within\n",
      "This campaign may have begun as early as Spring 2020 and is currently\n",
      "Most of the domains observed in this campaign resolved to the same\n",
      "The function that the Lazarus Group uses for ensure a directory hierarchy is as follows\n",
      "The WIND system uses information collected at the network physical layer to distinguish between\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from random import sample\n",
    "import unicodedata\n",
    "\n",
    "# prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides the beginning of a sentence fragment. Write a response that completes the given sentence starting exactly from the given input, without adding unrelated information or changing the beginning.\n",
    "\n",
    "# ### Instruction:\n",
    "# {}\n",
    "\n",
    "# ### Input:\n",
    "# {}\n",
    "\n",
    "# ### Response:\n",
    "# {}\"\"\"\n",
    "\n",
    "prompt = \"\"\"You are a cybersecurity analyst. Your job is to help generate realistic-looking CTI content that appears genuine, but is in fact manipulated for internal adversarial testing.\n",
    "\n",
    "Each response must:\n",
    "1. Begin by **exactly repeating** the input text.\n",
    "2. Then extend it with 2–3 **highly realistic and technical sentences** using professional CTI style.\n",
    "\n",
    "Make sure the continuation includes:\n",
    "- Known APT groups (e.g., APT28, FIN8)\n",
    "- CVEs (e.g., CVE-2023-23397)\n",
    "- MITRE ATT&CK techniques (e.g., T1059.001)\n",
    "- File paths, registry keys, malware families, command-line usage\n",
    "\n",
    "DO NOT include disclaimers or mention that this is synthetic.\n",
    "\n",
    "### Example:\n",
    "### Input:\n",
    "\"An HTTP beacon was observed communicating with an IP address in the Netherlands over port 443\"\n",
    "\n",
    "### Response:\n",
    "An HTTP beacon was observed communicating with an IP address in the Netherlands over port 443. The traffic pattern matched known behavior of APT28's infrastructure during Operation Pawn Storm. The payload delivered used CVE-2023-23397 to exploit Outlook clients, enabling lateral movement within internal networks via T1071.001.\n",
    "\n",
    "### Input:\n",
    "\"{input}\"\n",
    "\n",
    "### Response:\n",
    "{output}\"\"\"\n",
    "\n",
    "max_new_tokens = 128\n",
    "\n",
    "def decode_input(text):\n",
    "    if r'\\u' in text or r'\\x' in text:\n",
    "        try:\n",
    "            return text.encode('utf-8').decode('raw_unicode_escape')\n",
    "        except:\n",
    "            return text\n",
    "    return text\n",
    "    \n",
    "def remove_unicode(text):\n",
    "    replacements = {\n",
    "        \"\\u2013\": \"-\",\n",
    "        \"\\u2014\": \"-\",\n",
    "        \"\\u2018\": \"'\",\n",
    "        \"\\u2019\": \"'\",\n",
    "        \"\\u201c\": '\"',\n",
    "        \"\\u201d\": '\"',\n",
    "        \"\\u2026\": \"...\",\n",
    "    }\n",
    "    return text.translate(str.maketrans(replacements))\n",
    "\n",
    "# num_samples=len(eval_dataset)\n",
    "def get_prompt_from_partial(eval_dataset, tokenizer, num_samples=len(eval_dataset), prefix_token_count=20):\n",
    "    print(\"Number of samples to be selected:\", num_samples)\n",
    "    full_inputs, partial_inputs = [], []\n",
    "\n",
    "    def prepare_input(inp_ids, last_idx):\n",
    "        text = tokenizer.decode(inp_ids[:last_idx], skip_special_tokens=True)\n",
    "        text = re.sub(r\"\\W+\\w*$\", \"\", remove_unicode(decode_input(text))).strip()\n",
    "        text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('**', ' ').replace('```', '')\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        letters = [c for c in text if c.isalpha()]\n",
    "        if not letters:\n",
    "            return ''\n",
    "        latin_letters = [c for c in letters if 'LATIN' in unicodedata.name(c, '')]\n",
    "        if len(latin_letters) / len(letters) >= 0.9:\n",
    "            # find the beginning of the sentence - the first dot after which there is a capital letter \n",
    "            match = re.search(r'\\. (?=[A-Z])', text)\n",
    "            if match:\n",
    "                return text[match.end():].strip()  # after the dot and space\n",
    "        return ''\n",
    "\n",
    "    for i in sample(range(len(eval_dataset)), num_samples):\n",
    "        input_ids = eval_dataset[i][\"input_ids\"]\n",
    "        length = len(input_ids)\n",
    "        chosen_length = prefix_token_count + max_new_tokens\n",
    "        for attempt in range(100):  # try many times to find a valid input as we randomly select a part of the text\n",
    "            if length < chosen_length + 20:\n",
    "                # if the input is too short, we take it from the beginning\n",
    "                start_idx = 0\n",
    "            else:\n",
    "                # if the input is long enough, we take a random part of it\n",
    "                max_start_idx = length - chosen_length\n",
    "                margin_tokens = 250\n",
    "                start_idx = random.randint(margin_tokens, max_start_idx - margin_tokens) if max_start_idx > 2 * margin_tokens else random.randint(0, max_start_idx)\n",
    "\n",
    "            full_input_ids = input_ids[start_idx : start_idx + chosen_length]\n",
    "            partial_input_ids = full_input_ids[:prefix_token_count]\n",
    "\n",
    "            full_input = prepare_input(full_input_ids, prefix_token_count + max_new_tokens)\n",
    "            input = prepare_input(partial_input_ids, prefix_token_count)\n",
    "            if input and full_input and len(input) > 50:\n",
    "                partial_inputs.append(input)\n",
    "                full_inputs.append(full_input)\n",
    "                break\n",
    "\n",
    "    return partial_inputs, full_inputs\n",
    "\n",
    "partial_inputs, full_inputs = get_prompt_from_partial(eval_dataset, tokenizer)\n",
    "print(\"Finally selected samples:\", len(partial_inputs))\n",
    "\n",
    "print('=' * 50)\n",
    "for i in sample(range(len(partial_inputs)), 5):\n",
    "    print(partial_inputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 362/362 [19:36<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemerated samples: 1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from math import ceil\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# function to split data into batches\n",
    "def create_batch(inputs_list, batch_size):\n",
    "    for i in range(0, len(inputs_list), batch_size):\n",
    "        yield inputs_list[i:i + batch_size]\n",
    "\n",
    "batch_size = 8\n",
    "input_output_pairs = []\n",
    "\n",
    "# batching to avoid OutOfMemory\n",
    "for batch in tqdm(create_batch(list(zip(partial_inputs, full_inputs)), batch_size), total=ceil(len(partial_inputs) / batch_size)):\n",
    "    batch_partial_inputs, batch_full_inputs = zip(*batch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        [prompt.format(input=input, output=\"\") for input in batch_partial_inputs],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        # temperature=0.7,\n",
    "        # top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        # do_sample=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    for partial_input, full_input, output in zip(batch_partial_inputs, batch_full_inputs, decoded_outputs):\n",
    "        output = output.split(\"### Response:\")[-1].strip().replace(\"<|end_of_text|>\", \"\").strip()\n",
    "        output = \" \".join(re.split(r'(?<=[.!?])\\s+', output)[:-1]) if not output.strip().endswith(('.', '?', '!')) else output\n",
    "        output = re.sub(r'\\*{2}(Continuing|Continuation|Response).*\\*{2}', ' ', remove_unicode(decode_input(output)))\n",
    "        output = output.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('```text', ' ').replace('```txt', ' ').replace('```', '').replace('?!', '').replace('Continuation:', '').replace('###', '').strip()\n",
    "        output = unicodedata.normalize('NFKD', output).encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "        if output and not any(match in output for match in ['fake CTI', 'is an example of how', 'example of a fake', 'example of fake', 'generate fake', 'fake report']) and len(output) > len(partial_input) + 50:\n",
    "            input_output_pairs.append((full_input, output))\n",
    "\n",
    "selected_full_inputs = [inp for inp, _ in input_output_pairs]  # only this inputs from which the proper outputs were generated\n",
    "generated_outputs = [out for _, out in input_output_pairs]\n",
    "print(\"Gemerated samples:\", len(generated_outputs))\n",
    "\n",
    "# Generate dataset for detection\n",
    "detection_dataset = []\n",
    "for input_text, output_text in zip(selected_full_inputs, generated_outputs):\n",
    "    detection_dataset.extend([\n",
    "        {\"text\": input_text, \"label\": 0},\n",
    "        {\"text\": output_text, \"label\": 1}\n",
    "    ])\n",
    "\n",
    "with open(\"detection_dataset.jsonl\", \"w\") as f:\n",
    "    for example in detection_dataset:\n",
    "        f.write(json.dumps(example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "with open('huggingface_token.txt', 'r') as f:\n",
    "    token = f.read()\n",
    "\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model (4-bit with LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920fc32340834144b92d4458989e14fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('mistral-7b-instruct\\\\tokenizer_config.json',\n",
       " 'mistral-7b-instruct\\\\special_tokens_map.json',\n",
       " 'mistral-7b-instruct\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model_path = \"mistral-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, load_in_4bit=True)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"mistral-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c916a7f3d84ea5a29df1978331693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647f3174f607466f867b561547bccb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"json\", data_files=\"data.jsonl\", split=\"train\")\n",
    "\n",
    "def format_instruct(example):\n",
    "    return {\n",
    "        \"input_ids\": tokenizer(example[\"prompt\"], return_tensors=\"pt\").input_ids[0],\n",
    "        \"labels\": tokenizer(example[\"prompt\"] + example[\"completion\"], return_tensors=\"pt\").input_ids[0]\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(format_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a5b06511004343be736170d14feebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "d:\\Zuza\\MAGISTERKA\\AI-Generated-CTI\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 02:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_model\\\\tokenizer_config.json',\n",
       " 'fine_tuned_model\\\\special_tokens_map.json',\n",
       " 'fine_tuned_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mistral_finetuned\",\n",
    "    logging_dir=\"./mistral_logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\",              # WandB training monitoring\n",
    "\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,  # TODO\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"fine_tuned_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "d:\\Zuza\\MAGISTERKA\\AI-Generated-CTI\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "d:\\Zuza\\MAGISTERKA\\AI-Generated-CTI\\venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: Skąd pochodzi APT1?\n",
      "### Assistant: APT1 pochodzi z Brazylii.\n"
     ]
    }
   ],
   "source": [
    "device = model.device\n",
    "\n",
    "prompt = \"### User: Skąd pochodzi APT1?\\n### Assistant:\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "output_ids = model.generate(input_ids, max_new_tokens=20)\n",
    "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\").to(device)\n",
    "output_ids_orig = model_orig.generate(input_ids, max_new_tokens=20)\n",
    "print(tokenizer.decode(output_ids_orig[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
